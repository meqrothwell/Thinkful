{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 1000 points : 396\n"
     ]
    }
   ],
   "source": [
    "yelp_reviews = pd.read_csv('yelp_labelled.txt', delimiter=\"\\t\", header=None)\n",
    "yelp_reviews.columns = ['review', 'pos']\n",
    "\n",
    "keywords = ['good', 'best', 'wonderful', 'classic', 'gem', 'favorite', 'plus', 'yes', 'great', 'see', 'definitely', 'excellent', 'well', 'heaven', 'interesting', 'entertaining', 'lovely', 'recommend', 'again', 'loved', 'best', 'cool', 'perfect', '10', 'definitely']\n",
    "\n",
    "for key in keywords:\n",
    "    # Note that we add spacesconfusion_matrix(target, y_pred) around the key so that we're getting the word,\n",
    "    # not just pattern matching.\n",
    "    yelp_reviews[str(key)] = yelp_reviews.review.str.contains(\n",
    "        ' ' + str(key) + ' ',\n",
    "        case=True\n",
    "    )\n",
    "\n",
    "yelp_reviews['long'] = yelp_reviews.review.str.len() > 20\n",
    "yelp_reviews.pos = yelp_reviews.pos.astype(bool)\n",
    "\n",
    "data = yelp_reviews[keywords + ['long']]\n",
    "target = yelp_reviews['pos']\n",
    "\n",
    "# Our data is binary / boolean, so we're importing the Bernoulli classifier.\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "# Instantiate our model and store it in a new variable.\n",
    "bnb = BernoulliNB()\n",
    "\n",
    "# Fit our model to the data\n",
    "bnb.fit(data, target)\n",
    "\n",
    "# Classify, storing the result in a new variable.\n",
    "y_pred = bnb.predict(data)\n",
    "\n",
    "# Display our results.\n",
    "print(\"Number of mislabeled points out of a total {} points : {}\".format(\n",
    "    data.shape[0],\n",
    "    (target != y_pred).sum()\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[478  22]\n",
      " [374 126]]\n",
      "Sensitivity of A:  0.252\n",
      "Specificity of A:  0.956\n"
     ]
    }
   ],
   "source": [
    "A = confusion_matrix(target, y_pred)\n",
    "print(A)\n",
    "print(\"Sensitivity of A: \", A[1,1] / (A[1,0]+A[1,1]))\n",
    "print(\"Specificity of A: \", A[0,0] / (A[0,1]+A[0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 1000 points : 488\n"
     ]
    }
   ],
   "source": [
    "keywords = ['Good', 'Best', 'Wonderful', 'Classic', 'Gem', 'Favorite', 'Plus', 'Yes', 'Great', 'See', 'Definitely', 'Excellent', 'Well', 'Heaven', 'Interesting', 'Entertaining', 'Lovely', 'Recommend', 'Again', 'Loved', 'Best', 'Cool', 'Perfect', '10', 'Definitely']\n",
    "\n",
    "for key in keywords:\n",
    "    # Note that we add spaces around the key so that we're getting the word,\n",
    "    # not just pattern matching.\n",
    "    yelp_reviews[str(key)] = yelp_reviews.review.str.contains(\n",
    "        ' ' + str(key) + ' ',\n",
    "        case=True\n",
    "    )\n",
    "\n",
    "yelp_reviews['long'] = yelp_reviews.review.str.len() > 20\n",
    "yelp_reviews.pos = yelp_reviews.pos.astype(bool)\n",
    "\n",
    "data = yelp_reviews[keywords + ['long']]\n",
    "target = yelp_reviews['pos']\n",
    "\n",
    "# Our data is binary / boolean, so we're importing the Bernoulli classifier.\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "# Instantiate our model and store it in a new variable.\n",
    "bnb = BernoulliNB()\n",
    "\n",
    "# Fit our model to the data\n",
    "bnb.fit(data, target)\n",
    "\n",
    "# Classify, storing the result in a new variable.\n",
    "y_pred = bnb.predict(data)\n",
    "\n",
    "# Display our results.\n",
    "print(\"Number of mislabeled points out of a total {} points : {}\".format(\n",
    "    data.shape[0],\n",
    "    (target != y_pred).sum()\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 55 445]\n",
      " [ 43 457]]\n",
      "Sensitivity of A:  0.914\n",
      "Specificity of A:  0.11\n"
     ]
    }
   ],
   "source": [
    "A = confusion_matrix(target, y_pred)\n",
    "print(A)\n",
    "print(\"Sensitivity of A: \", A[1,1] / (A[1,0]+A[1,1]))\n",
    "print(\"Specificity of A: \", A[0,0] / (A[0,1]+A[0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 1000 points : 391\n"
     ]
    }
   ],
   "source": [
    "keywords = ['Good', 'Best', 'Wonderful', 'Classic', 'Gem', 'Favorite', 'Plus', 'Yes', 'Great', 'See', 'Definitely', 'Excellent', 'Well', 'Heaven', 'Interesting', 'Entertaining', 'Lovely', 'Recommend', 'Again', 'Loved', 'Best', 'Cool', 'Perfect', '10', 'Definitely', 'good', 'best', 'wonderful', 'classic', 'gem', 'favorite', 'plus', 'yes', 'great', 'see', 'definitely', 'excellent', 'well', 'heaven', 'interesting', 'entertaining', 'lovely', 'recommend', 'again', 'loved', 'best', 'cool', 'perfect', '10', 'definitely']\n",
    "\n",
    "for key in keywords:\n",
    "    # Note that we add spaces around the key so that we're getting the word,\n",
    "    # not just pattern matching.\n",
    "    yelp_reviews[str(key)] = yelp_reviews.review.str.contains(\n",
    "        ' ' + str(key) + ' ',\n",
    "        case=True\n",
    "    )\n",
    "\n",
    "yelp_reviews['long'] = yelp_reviews.review.str.len() > 20\n",
    "yelp_reviews.pos = yelp_reviews.pos.astype(bool)\n",
    "\n",
    "data = yelp_reviews[keywords + ['long']]\n",
    "target = yelp_reviews['pos']\n",
    "\n",
    "# Our data is binary / boolean, so we're importing the Bernoulli classifier.\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "# Instantiate our model and store it in a new variable.\n",
    "bnb = BernoulliNB()\n",
    "\n",
    "# Fit our model to the data\n",
    "bnb.fit(data, target)\n",
    "\n",
    "# Classify, storing the result in a new variable.\n",
    "y_pred = bnb.predict(data)\n",
    "\n",
    "# Display our results.\n",
    "print(\"Number of mislabeled points out of a total {} points : {}\".format(\n",
    "    data.shape[0],\n",
    "    (target != y_pred).sum()\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[478  22]\n",
      " [369 131]]\n",
      "Sensitivity of A:  0.262\n",
      "Specificity of A:  0.956\n"
     ]
    }
   ],
   "source": [
    "A = confusion_matrix(target, y_pred)\n",
    "print(A)\n",
    "print(\"Sensitivity of A: \", A[1,1] / (A[1,0]+A[1,1]))\n",
    "print(\"Specificity of A: \", A[0,0] / (A[0,1]+A[0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "amzn_reviews = pd.read_csv('amazon_cells_labelled.txt', delimiter=\"\\t\", header=None)\n",
    "amzn_reviews.columns = ['review', 'pos']\n",
    "\n",
    "imdb_reviews = pd.read_csv('imdb_labelled.txt', delimiter=\"\\t\", header=None)\n",
    "imdb_reviews.columns = ['review', 'pos']\n",
    "\n",
    "all_reviews = pd.concat([yelp_reviews,imdb_reviews,amzn_reviews])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 2748 points : 1090\n"
     ]
    }
   ],
   "source": [
    "keywords = ['Good', 'Best', 'Wonderful', 'Classic', 'Gem', 'Favorite', 'Plus', 'Yes', 'Great', 'See', 'Definitely', 'Excellent', 'Well', 'Heaven', 'Interesting', 'Entertaining', 'Lovely', 'Recommend', 'Again', 'Loved', 'Best', 'Cool', 'Perfect', '10', 'Definitely', 'good', 'best', 'wonderful', 'classic', 'gem', 'favorite', 'plus', 'yes', 'great', 'see', 'definitely', 'excellent', 'well', 'heaven', 'interesting', 'entertaining', 'lovely', 'recommend', 'again', 'loved', 'best', 'cool', 'perfect', '10', 'definitely']\n",
    "\n",
    "for key in keywords:\n",
    "    # Note that we add spaces around the key so that we're getting the word,\n",
    "    # not just pattern matching.\n",
    "    all_reviews[str(key)] = all_reviews.review.str.contains(\n",
    "        ' ' + str(key) + ' ',\n",
    "        case=True\n",
    "    )\n",
    "\n",
    "all_reviews['long'] = all_reviews.review.str.len() > 20\n",
    "all_reviews.pos = all_reviews.pos.astype(bool)\n",
    "\n",
    "data = all_reviews[keywords + ['long']]\n",
    "target = all_reviews['pos']\n",
    "\n",
    "# Our data is binary / boolean, so we're importing the Bernoulli classifier.\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "# Instantiate our model and store it in a new variable.\n",
    "bnb = BernoulliNB()\n",
    "\n",
    "# Fit our model to the data\n",
    "bnb.fit(data, target)\n",
    "\n",
    "# Classify, storing the result in a new variable.\n",
    "y_pred = bnb.predict(data)\n",
    "\n",
    "# Display our results.\n",
    "print(\"Number of mislabeled points out of a total {} points : {}\".format(\n",
    "    data.shape[0],\n",
    "    (target != y_pred).sum()\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1287   75]\n",
      " [1015  371]]\n",
      "Sensitivity of A:  0.267676767677\n",
      "Specificity of A:  0.944933920705\n"
     ]
    }
   ],
   "source": [
    "A = confusion_matrix(target, y_pred)\n",
    "print(A)\n",
    "print(\"Sensitivity of A: \", A[1,1] / (A[1,0]+A[1,1]))\n",
    "print(\"Specificity of A: \", A[0,0] / (A[0,1]+A[0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2198, 51) (2198,)\n",
      "(550, 51) (550,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     data, target, test_size=0.2)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 2198 points : 866\n"
     ]
    }
   ],
   "source": [
    "# Instantiate our model and store it in a new variable.\n",
    "bnb = BernoulliNB()\n",
    "\n",
    "# Fit our model to the data\n",
    "bnb.fit(X_train, y_train)\n",
    "\n",
    "# Classify, storing the result in a new variable.\n",
    "y_pred = bnb.predict(X_train)\n",
    "\n",
    "# Display our results.\n",
    "print(\"Number of mislabeled points out of a total {} points : {}\".format(\n",
    "    X_train.shape[0],\n",
    "    (y_train != y_pred).sum()\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I made my classifiers similar, only varying the capitalization of the words. I was curious to see how capitalization alone would affect performance. I tested each classifier on the same dataset for the first three experiments to make results more comparable. I then combined the three review datasets into on to test the best classifier of the initial three on a larger set. \n",
    "\n",
    "For the first three experiements, I tested my keywords as uncapitalized, capitalized, and both. Of the three, the classifier that tested for both capitalizations performed the best, as expected. It was only slightly better than the classifier that only used uncapitalized words, which is also expected, since most words are not capitalized. The classifier than only used capitalized words performed the worst by a large margin. When I tested the classifier with both capitalizations on the combined dataset, the results were very similar overall, with the sensitivity being slightly higher and specificity slightly lower compared to the smaller set. Finally, I tested the model on a train-test-split, and it performed similarly well there. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
